{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai2.text.all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create databunch form LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BPTT=10\n",
    "BS=64\n",
    "\n",
    "EN_FILE = Path('data/en-clean.txt')\n",
    "EN_TEXT = EN_FILE.read()[1:].replace('\\n', '').replace('  ', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1039052"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(EN_TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "toks = tokenize1(EN_TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#10) ['xxbos','the','project','gutenberg','ebook','of','peter','pan',',','by']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toks[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4008"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = make_vocab(Counter(toks), min_freq=3, max_vocab=4000)\n",
    "\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xxunk',\n",
       " 'xxpad',\n",
       " 'xxbos',\n",
       " 'xxeos',\n",
       " 'xxfld',\n",
       " 'xxrep',\n",
       " 'xxwrep',\n",
       " 'xxup',\n",
       " 'xxmaj',\n",
       " ',',\n",
       " '.',\n",
       " 'the',\n",
       " 'and',\n",
       " 'to',\n",
       " 'a']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arbitrary way of splitting text into 'examples', would probably be better to split by chapters\n",
    "# or something along these lines but shouldn't make much of a difference\n",
    "txts = np.array_split(EN_TEXT.split(), 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dblock = DataBlock(blocks=(TextBlock(vocab, is_lm=True)), splitter=RandomSplitter(seed=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbunch_lm = dblock.databunch(txts, seq_len=BPTT, bs=BS) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbunch_lm.one_batch()[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "WD=1e-7\n",
    "\n",
    "def opt(params, lr):\n",
    "    return Adam(params, lr, mom=0.8, sqr_mom=0.99)\n",
    "\n",
    "drops = np.array([0.25, 0.1, 0.2, 0.02, 0.15])\n",
    "\n",
    "config = dict(\n",
    "    emb_sz=100,\n",
    "    n_hid=1024,\n",
    "    n_layers=3,\n",
    "    input_p=drops[0],\n",
    "    hidden_p=drops[1],\n",
    "    weight_p=drops[2],\n",
    "    embed_p=drops[3])\n",
    "\n",
    "awd_lstm_lm_config.update(config)\n",
    "\n",
    "learn = language_model_learner(\n",
    "    dbunch_lm,\n",
    "    AWD_LSTM,\n",
    "    opt_func=opt,\n",
    "    pretrained=False,\n",
    "    config=awd_lstm_lm_config,\n",
    "    drop_mult=0.2,\n",
    "    metrics=[accuracy, Perplexity()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.941036</td>\n",
       "      <td>5.653147</td>\n",
       "      <td>0.097439</td>\n",
       "      <td>285.187469</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.535548</td>\n",
       "      <td>5.302301</td>\n",
       "      <td>0.138911</td>\n",
       "      <td>200.798294</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5.280907</td>\n",
       "      <td>5.062784</td>\n",
       "      <td>0.161350</td>\n",
       "      <td>158.029816</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5.074124</td>\n",
       "      <td>4.859920</td>\n",
       "      <td>0.194987</td>\n",
       "      <td>129.013885</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.882607</td>\n",
       "      <td>4.752127</td>\n",
       "      <td>0.205382</td>\n",
       "      <td>115.830414</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(5, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('5epochs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate loss given embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = learn.load('5epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'L' object has no attribute 'softmax'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-facac0d6fb55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_preds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/workspace/fastai2/fastai2/learner.py\u001b[0m in \u001b[0;36mget_preds\u001b[0;34m(self, ds_idx, dl, with_input, with_decoded, with_loss, act, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m             \u001b[0mpred_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mwith_input\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpred_i\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m                 \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpred_i\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpred_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mwith_decoded\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_i\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'decodes'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpred_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/fastai2/fastai2/layers.py\u001b[0m in \u001b[0;36mactivation\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;31m# Cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai2/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36msoftmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1229\u001b[0m         \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_softmax_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1230\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1231\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1232\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1233\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'L' object has no attribute 'softmax'"
     ]
    }
   ],
   "source": [
    "preds, targs = learn.get_preds()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the time being I get an error as above - will implement manual loss calculation and replace this once it gets fixed ([github issue](https://github.com/fastai/fastai2/issues/35))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss():\n",
    "    preds = []\n",
    "    targs = []\n",
    "\n",
    "    learn.model.eval()\n",
    "    with torch.no_grad():\n",
    "        for b in learn.dbunch.valid_dl:\n",
    "            preds.append(learn.model(b[0])[0])\n",
    "            targs.append(b[1])\n",
    "\n",
    "    preds = torch.cat(preds, 1)\n",
    "    targs = torch.cat(targs, 1)\n",
    "    \n",
    "    return CrossEntropyLossFlat()(preds, targs).item(), accuracy(preds,targs).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_layer = learn.model[0].encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4008, 100])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_layer.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.753739833831787, 0.20564089715480804)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_layer_weights = emb_layer.weight.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_layer.weight[:15].zero_();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5.313080310821533, 0.1253531128168106)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_layer.weight = nn.Parameter(emb_layer_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.753595352172852, 0.20559674501419067)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permute embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PermuteEmbedding(nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_dim, padding_idx):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_embeddings = num_embeddings\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.padding_idx = padding_idx\n",
    "        \n",
    "        # to conform to nn.Embedding api\n",
    "        self.max_norm=None\n",
    "        self.norm_type=2.0\n",
    "        self.scale_grad_by_freq=False\n",
    "        self.sparse = False\n",
    "\n",
    "        self.weight = nn.Parameter( torch.Tensor(num_embeddings, embedding_dim) )\n",
    "        self.p = nn.Parameter( torch.eye(self.num_embeddings) )\n",
    "        self.p.requires_grad = False\n",
    "        \n",
    "        self.reset_parameters()\n",
    "        \n",
    "    def forward(self, words):\n",
    "        return F.embedding(words, self.p @ self.weight)\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        self.weight.data.normal_(0,1)\n",
    "        self.p.data = torch.eye(self.num_embeddings)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pAWD_LSTM(AWD_LSTM):\n",
    "    def __init__(self, vocab_sz, emb_sz, n_hid, n_layers, pad_token=1, hidden_p=0.2, input_p=0.6, embed_p=0.1,\n",
    "                 weight_p=0.5, bidir=False, packed=False):\n",
    "        store_attr(self, 'emb_sz,n_hid,n_layers,pad_token,packed')\n",
    "        self.bs = 1\n",
    "        self.n_dir = 2 if bidir else 1\n",
    "#         self.encoder = nn.Embedding(vocab_sz, emb_sz, padding_idx=pad_token)\n",
    "        self.encoder = PermuteEmbedding(vocab_sz, emb_sz, padding_idx=pad_token)\n",
    "        self.encoder_dp = EmbeddingDropout(self.encoder, embed_p)\n",
    "        self.rnns = nn.ModuleList([self._one_rnn(emb_sz if l == 0 else n_hid, (n_hid if l != n_layers - 1 else emb_sz)//self.n_dir,\n",
    "                                                 bidir, weight_p, l) for l in range(n_layers)])\n",
    "        self.encoder.weight.data.uniform_(-self.initrange, self.initrange)\n",
    "        self.input_dp = RNNDropout(input_p)\n",
    "        self.hidden_dps = nn.ModuleList([RNNDropout(hidden_p) for l in range(n_layers)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastai2\n",
    "fastai2.text.models.core._model_meta[pAWD_LSTM] = fastai2.text.models.core._model_meta[AWD_LSTM]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "WD=1e-7\n",
    "\n",
    "def opt(params, lr):\n",
    "    return Adam(params, lr, mom=0.8, sqr_mom=0.99)\n",
    "\n",
    "drops = np.array([0.25, 0.1, 0.2, 0.02, 0.15])\n",
    "\n",
    "config = dict(\n",
    "    emb_sz=100,\n",
    "    n_hid=1024,\n",
    "    n_layers=3,\n",
    "    input_p=drops[0],\n",
    "    hidden_p=drops[1],\n",
    "    weight_p=drops[2],\n",
    "    embed_p=drops[3])\n",
    "\n",
    "awd_lstm_lm_config.update(config)\n",
    "\n",
    "learn = language_model_learner(\n",
    "    dbunch_lm,\n",
    "    pAWD_LSTM,\n",
    "    opt_func=opt,\n",
    "    pretrained=False,\n",
    "    config=awd_lstm_lm_config,\n",
    "    drop_mult=0.2,\n",
    "    metrics=[accuracy, Perplexity()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.930654</td>\n",
       "      <td>5.631249</td>\n",
       "      <td>0.098220</td>\n",
       "      <td>279.010376</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.544677</td>\n",
       "      <td>5.282267</td>\n",
       "      <td>0.146593</td>\n",
       "      <td>196.815567</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5.242517</td>\n",
       "      <td>5.033709</td>\n",
       "      <td>0.164800</td>\n",
       "      <td>153.501236</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5.064619</td>\n",
       "      <td>4.863100</td>\n",
       "      <td>0.191385</td>\n",
       "      <td>129.424744</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.917329</td>\n",
       "      <td>4.752985</td>\n",
       "      <td>0.202799</td>\n",
       "      <td>115.929817</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(5, 1e-3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
