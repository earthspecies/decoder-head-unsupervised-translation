{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having trained the English and Spanish LMs (along with the embeddings which constitute part of the encoder), it is now time to attempt translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decoder_head.core import *\n",
    "from fastai2.text.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_en= make_vocab(pd.read_pickle('data/en-100_tok/counter.pkl'), max_vocab=4000)\n",
    "vocab_es= make_vocab(pd.read_pickle('data/es-100_tok/counter.pkl'), max_vocab=4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/en-100_tok/'\n",
    "mult = 4\n",
    "bs = 80\n",
    "seq_len = 70\n",
    "\n",
    "lm = DataBlock(blocks=(TextBlock(vocab=vocab_en, is_lm=True),),\n",
    "                get_x=read_tokenized_file,\n",
    "                get_items=partial(get_text_files, folders=['train', 'valid']),\n",
    "                splitter=FuncSplitter(lambda itm: itm.parent.name == 'valid'))\n",
    "\n",
    "dbunch_lm = lm.databunch(path, path=path, bs=bs, seq_len=seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = language_model_learner(\n",
    "    dbunch_lm,\n",
    "    pAWD_LSTM,\n",
    "    opt_func=opt,\n",
    "    pretrained=False,\n",
    "    config=awd_lstm_lm_config,\n",
    "    drop_mult=0.1,\n",
    "    metrics=[accuracy, top_k_accuracy]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp decoder_head.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I construct the dictionary to evaluate translation performance using the wonderful data made available as part of the awesome [MUSE](https://github.com/facebookresearch/MUSE) repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def get_en_es_dict():\n",
    "    with open('data/en-es.txt') as f:\n",
    "        en_es = f.readlines()\n",
    "    en_es = [l.strip() for l in en_es]\n",
    "    \n",
    "    en_es_dict = defaultdict(list)\n",
    "    for l in en_es:\n",
    "        source, target = l.split()\n",
    "        en_es_dict[source].append(target)\n",
    "        \n",
    "    # check that we have the source word in the model trained on English\n",
    "    vocab_en_set = set(vocab_en)\n",
    "    en_es_dict = {k: v for k, v in en_es_dict.items() if k in vocab_en_set}\n",
    "    \n",
    "    # make sure we have the target word in Spanish\n",
    "    vocab_es_set = set(vocab_es)\n",
    "    en_es_dict = {k: vocab_es_set.intersection(set(v)) for k, v in en_es_dict.items() if vocab_es_set.intersection(set(v))}\n",
    "    \n",
    "    return en_es_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_es_dict = get_en_es_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2451"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(en_es_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attemp translation from English to Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fastai2.text.learner.LMLearner at 0x7f3887c4f090>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.load('pLSTM_en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up the stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model[0].encoder.weight.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.optimize_permutation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model[0].encoder.weight.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.init.kaiming_normal_(learn.model[0].encoder.p);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replacing the embeddings with the Spanish embeddings learned by the Spanish LM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model[0].encoder.weight.data = torch.load('data/embeddings_es.torch').data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model[0].encoder.p.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model[0].encoder.weight.requires_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have an English LM with Spanish embeddings loaded. Let's see how we do on translation.\n",
    "\n",
    "One thing worth keeping in mind are the missing English words from the Spanish vocabulary. This is an interesting situation and makes the task even harder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.loss_func = lambda preds, targs: aza_loss(learn, preds, targs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>top_k_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.984266</td>\n",
       "      <td>4.949764</td>\n",
       "      <td>0.250956</td>\n",
       "      <td>0.460905</td>\n",
       "      <td>41:12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 1e-3,  moms=(0.8, 0.7, 0.8), wd=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.save('pLSTM_en-es')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fastai2.text.learner.LMLearner at 0x7ff863701150>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.load('pLSTM_en-es')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(#3) [4.975531101226807,0.24766667187213898,0.45390090346336365]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_n_translation_acc(top_n=1):\n",
    "    p = learn.model[0].encoder.p\n",
    "    hits = 0\n",
    "    for k, v in en_es_dict.items():\n",
    "        idx_en = vocab_en.index(k)\n",
    "        for vv in v:\n",
    "            idx_es = vocab_es.index(vv)\n",
    "            if idx_es in p[idx_en].argsort(descending=True)[:top_n]:\n",
    "                hits += 1\n",
    "#                 print(k, vv)\n",
    "                break\n",
    "    return hits/len(en_es_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.037943696450428395"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_n_translation_acc(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_n_translation_acc(top_n=1):\n",
    "    p = learn.model[0].encoder.p\n",
    "    hits = 0\n",
    "    for k, v in en_es_dict.items():\n",
    "        idx_en = vocab_en.index(k)\n",
    "        for vv in v:\n",
    "            idx_es = vocab_es.index(vv)\n",
    "            if idx_es in p[idx_en].argsort(descending=True)[:top_n]:\n",
    "                hits += 1\n",
    "                print(k, [vocab_es[i] for i in p[idx_en].argsort(descending=True)[:5]])\n",
    "                break\n",
    "    return hits/len(en_es_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'han', 'tener', 'tienen'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_es_dict['have']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "has ['utilizan', 'deben', 'símbolo', 'permiten', 'tiene']\n",
      "one ['cuando', 'para', 'lo', 'una', 'algo']\n",
      "united ['evitar', 'animales', 'tratar', 'fuego', 'unidos']\n",
      "spanish ['juvenil', 'high', 'masculino', 'española', 'blancas']\n",
      "publishing ['núcleos', 'documentos', 'diez', 'publicaciones', 'satélite']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.002039983680130559"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_n_translation_acc(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def top_n_translation_acc(top_n=1):\n",
    "    p = learn.model[0].encoder.p\n",
    "    hits = 0\n",
    "    for k, v in en_es_dict.items():\n",
    "        idx_en = vocab_en.index(k)\n",
    "        print(k, [vocab_es[i] for i in p[idx_en].argsort(descending=True)[:5]])\n",
    "        for vv in v:\n",
    "            idx_es = vocab_es.index(vv)\n",
    "            if idx_es in p[idx_en].argsort(descending=True)[:top_n]:\n",
    "                hits += 1\n",
    "                break\n",
    "    return hits/len(en_es_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_n calculated a take on nearest neighbors, performs better but not by much\n",
    "\n",
    "def top_n_translation_acc(top_n=1):\n",
    "    p = learn.model[0].encoder.p\n",
    "    learned_embeddings = learn.model[0].encoder.p @ learn.model[0].encoder.weight\n",
    "    \n",
    "    hits = 0\n",
    "    for k, v in en_es_dict.items():\n",
    "        idx_en = vocab_en.index(k)\n",
    "        diff = learn.model[0].encoder.weight - learned_embeddings[idx_en]\n",
    "        candidates = diff.sum(-1).argsort(descending=False)[:top_n]\n",
    "        \n",
    "        for vv in v:\n",
    "            idx_es = vocab_es.index(vv)\n",
    "            if idx_es in candidates:\n",
    "                hits += 1\n",
    "                break\n",
    "    return hits/len(en_es_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.025703794369645042"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_n_translation_acc(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, this attempt at translation failed. In the next notebook, we will make another attempt, this time with normalized embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_data.ipynb.\n",
      "Converted 01_train_LM_en.ipynb.\n",
      "Converted 02_train_LM_es.ipynb.\n",
      "Converted 03_translate_en_to_es.ipynb.\n",
      "Converted 99_index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
